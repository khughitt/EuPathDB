#' Create a series of POST requests which download all the annotation data for a species.
#'
#' The only way I have figured out how to download mass data from the eupathdb
#' is to ask for a raw dump of all available data using the GenesByGeneType
#' WADL.  Therefore, this function iterates over the various sequence types that
#' I have noticed at the eupathdb and does that for each type.
#'
#' @param entry Eupathdb annotation entry.
#' @param build_dir Location to dump the resulting data.
#' @param overwrite Overwrite existing data if it exists?
post_eupath_annotations <- function(entry = NULL, overwrite = FALSE, verbose = FALSE) {
  rda <- check_rda("annotations", entry, build_dir, overwrite)
  savefile <- rda[["savefile"]]
  if (!is.null(rda[["result"]])) {
    if (isTRUE(verbose)) {
      message("Returning primary annotation the data from a previous savefile.")
    }
    return(rda[["result"]])
  }

  ## query body as a structured list
  ## This list was generated by going to:
  ## view-source:http://tritrypdb.org/webservices/GeneQuestions/GenesByMolecularWeight.wadl
  ## scrolling down to the 'o-fields' section, and writing down the most likely
  ## useful column names.
  ## I later came through and wrote a function function to automagically populate this list.
  species <- entry[["TaxonUnmodified"]]
  webservice <- tolower(entry[["DataProvider"]])
  ## Use a query to find what annotation types are available: protein coding vs. rRNA vs. etc...
  types <- get_eupath_gene_types(webservice = webservice)
  result <- data.frame()

  ## Excepting schistodb, all the services are .orgs which is a .net.
  tld <- "org"
  if (webservice == "schistodb") {
    tld <- "net"
  }
  ## Finalize the URL to query using the webservice, tld, etc.
  service_directory <- prefix_map(webservice)
  ## download_json <- glue::glue("{build_dir}/{species_filename}.json")
  base_url <- glue::glue("https://{webservice}.{tld}/{service_directory}/service/record-types/transcript/searches/GenesByTaxon/reports/standard")
  wanted_columns <- get_semantic_columns(webservice = webservice)
  split_columns <- split(wanted_columns, ceiling(seq_along(wanted_columns) / 20))
  ##wanted_columns <- c("primary_key", "wdk_weight", "has_missing_transcripts", "gene_name",
  ##                    "gene_source_id", "gene_previous_ids", "gene_product", "transcript_product",
  ##                    "gene_exon_count", "exon_count", "gene_transcript_count",
  ##                    "three_prime_utr_length", "five_prime_utr_length", "strand", "gene_type",
  ##                    "is_pseudo", "transcript_length", "gene_entrez_id", "uniprot_id",
  ##                    "chromosome", "gene_location_text", "location_text", "sequence_id",
  ##                    "organism", "gene_ortholog_number", "gene_orthomcl_name",
  ##                    "gene_paralog_number", "gene_hts_noncoding_snps",
  ##                    "gene_hts_nonsyn_syn_ratio", "gene_hts_nonsynonymous_snps",
  ##                    "gene_hts_stop_codon_snps", "gene_hts_synonymous_snps",
  ##                    "gene_total_hts_snps", "cds", "transcript_sequence", "protein_sequence",
  ##                    "protein_length", "cds_length", "molecular_weight", "isoelectric_point",
  ##                    "interpro_id", "interpro_description", "pfam_id", "pfam_description",
  ##                    "pirsf_id", "pirsf_description", "prositeprofiles_id",
  ##                    "prositeprofiles_description", "smart_id", "smart_description",
  ##                    "superfamily_id", "superfamily_description", "tigrfam_id",
  ##                    "tigrfam_description", "new_product_name", "tm_count", "signalp_peptide",
  ##                    "signalp_scores", "predicted_go_id_component", "predicted_go_component",
  ##                    "predicted_go_id_function", "predicted_go_function",
  ##                    "predicted_go_id_process", "predicted_go_process",
  ##                    "annotated_go_id_component", "annotated_go_component",
  ##                    "annotated_go_id_function", "annotated_go_function",
  ##                    "annotated_go_id_process", "annotated_go_process", "ec_numbers",
  ##                    "ec_numbers_derived")
  all_records <- data.frame()
  for (g in seq_len(length(split_columns))) {
    group <- split_columns[[g]]
    group_string <- gsub(pattern = " ", replacement = "",
                         x = toString(paste0('"', group, '"')))
    ## Ohhhhh I see the problem, in a fashion similar to the bug with Schizosaccharomyces pombe,
    ## the TriTrypDB is not including the '/' symbols in the strain ID when it returns the metadata.

    ## Here is the string returned when examining the API help:
    ## https://fungidb.org/fungidb/app/web-services-help?searchName=GenesByTaxon&weight=10&organism=%5B%22Allomyces%20macrogynus%20ATCC%2038327%22%2C%22Blastocladiomycota%22%5D
    ## Note that the json printed here is not really... valid.  But unless something very close to it is provided the API will fail.
    ## The most problematic part is of course the json escaped quotes.
    ## As far as I can tell, my json is exactly identical to their json, but still it does not effing work.
    ##
    ## {
    ## "searchConfig": {
    ##   "parameters": {
    ##     "organism": "[\"Allomyces macrogynus ATCC 38327\",\"Blastocladiomycota\"]"
    ##   },
    ##   "wdkWeight": 10
    ## },
    ## "reportConfig": {
    ##   "attributes": [
    ##       "primary_key"
    ##       ],
    ##   "tables": []
    ## }
    ## }
    post_json <- glue::glue('{{
  "searchConfig": {{
    "parameters": {{
      "organism": "[\\"{species}\\"]"
    }},
    "wdkWeight": 10
  }},
  "reportConfig": {{
    "attributes": [ {group_string} ],
    "tables": []
  }}
}}')
    result <- httr::POST(url = base_url, body = post_json,
                         httr::content_type("application/json"),
                         httr::timeout(1200))
    ## Here is the string theoretically expected for a GET:
    ## Note that it is also problematic because of its inconsistent use of html encoded quotes and brackets.
    ## https://fungidb.org/fungidb/service/record-types/transcript/searches/GenesByTaxon/reports/standard?organism=%5B%22Allomyces%20macrogynus%20ATCC%2038327%22%2C%22Blastocladiomycota%22%5D&reportConfig={"attributes":["primary_key"],"tables":[]}
    ## species_coded <- URLencode(species)
    ## get_string <- glue(
    ##   '{base_url}?organism=%5B%22{species_coded}%22%5D&reportConfig={{"attributes":[{group_string}],"tables":[]}')
    ## result <- httr::GET(url=get_string)
    ## cont <- httr::content(result, encoding = "UTF-8", as = "text")
    ## Test the result to see that we actually got data.
    if (result[["status_code"]] == "422") {
      warn(sprintf("API request failed for %s (code = 422): ", entry[["Taxon"]]))
      next
    } else if (result[["status_code"]] == "400") {
      ## likely due to bad formatConfig
      warn("API Request failed for ", entry[["TaxonUnmodified"]], ": (code = 400)")
      next
    } else if (result[["status_code"]] == "404") {
      warn("API Request failed for ", entry[["TaxonUnmodified"]], ": (code = 404)")
      next
    } else if (result[["status_code"]] != "200") {
      warn("API Request failed for ", entry[["TaxonUnmodified"]], ": (code = ",
           result[["status_code"]], ")")
      next
    } else if (length(result[["content"]]) < 100) {
      warn("Very small amount of content returned for :", entry[["Taxon"]])
      next
    }
    cont <- httr::content(result, encoding = "UTF-8", as = "text")
    ## result <- try(jsonlite::fromJSON(cont, flatten = TRUE))
    result <- try(jsonlite::fromJSON(cont, flatten = TRUE))

    ## Every record contains and id, some fields, and tables.
    records <- result[["records"]]
    colnames(records) <- gsub(pattern = "^attributes\\.", replacement = "", x = colnames(records))
    colnames(records) <- gsub(pattern = "\\.", replacement = "_", x = colnames(records))
    records <- expand_list_columns(records)
    ## Drop some annoying columns
    records[["recordClassName"]] <- NULL

    if (g == 1) {
      all_records <- records
      ## "displayName" "overview" "gene_location_text" "gene_name" "organism" "
      ## "gene_transcript_count" "lc_project_id" "gene_exon_count" "chromosome"
      ## "primary_key" "gene_type" "project_id" "is_deprecated" "gene_source_id" "transcript_link"
      ## "sequence_id" "is_pseudo" "snpoverview" "gene_product" "source_id" "gene_ortholog_number"
    } else {
      ## shared_columns <- colnames(records) %in% colnames(all_records)
      ## records[, shared_columns] <- NULL
      records[["gene_source_id"]] <- NULL
      records[["source_id"]] <- NULL
      records[["project_id"]] <- NULL
      all_records <- merge(all_records, records, by = "displayName")
    }
    snooze <- Sys.sleep(1)
  } ## End of my nasty hack to get around some webservices crashing
  ## when I ask for all the columns.

  records <- all_records
  ## Use a heuristic to figure out numeric columns and set them accordingly.
  cnames <- colnames(records)
  for (i in seq_len(length(cnames))) {
    cname <- cnames[i]
    column <- records[[cname]]
    idx <- !is.na(column)
    column <- column[idx]
    res <- suppressWarnings(!is.na(as.numeric(as.character(column))))
    if (sum(res) == length(column)) {
      message("Setting ", cname, " to numeric.")
      records[[cname]] <- as.numeric(records[[cname]])
    }
  }

  ## Change entries which say 'N/A' to the actual NA value
  na_idx <- records == "N/A" | records == "NA"
  false_idx <- is.na(records)
  na_idx[false_idx] <- FALSE
  records[na_idx] <- NA

  ## Hopefully the data is consistent now, so let us change the column names
  ## and send the NAs to a contextually sensible value that sqlite will not yell about
  ## e.g. if a column is numeric, set it to 0; if a column is a character, set it to ""
  colnames(records) <- paste0("annot_", colnames(records))
  for (col_num in seq_len(length(colnames(records)))) {
    cname <- colnames(records)[col_num]
    na_idx <- is.na(records[[col_num]])
    if (is.character(records[[col_num]])) {
      records[na_idx, col_num] <- ""
    } else {
      records[na_idx, col_num] <- 0
    }
    ## Cast factor columns explicitly as factors
    test_col <- as.factor(records[[col_num]])
    test_levels <- length(levels(test_col))
    if (test_levels < 50) {
      message("Setting ", cname, " to a factor.")
      records[[col_num]] <- as.factor(records[[col_num]])
    }
  }

  ## orgdbs likes uppercase column names
  colnames(records) <- toupper(colnames(records))
  ## Drop a few extra dumb columns
  drop_columns <- c("ANNOT_ORGANISM", "ANNOT_ORGANISM_FULL", "ANNOT_ORGANISM_TEXT",
                    "ANNOT_RECORDCLASSNAME", "ANNOT_PROJECT_ID", "ANNOT_PROJECT",
                    "ANNOT_LC_PROJECT_ID", "ANNOT_GENE_SOURCE_ID", "ANNOT_SOURCE_ID")
  for (d in drop_columns) {
    if (!is.null(records[[d]])) {
      records[[d]] <- NULL
    }
  }

  ## Do an extra pass for weird NAs
  for (cname in colnames(records)) {
    na_idx <- grepl("^#N/A", records[[cname]])
    records[na_idx, cname] <- ""
  }

  ## I would like to get rid of any html tags
  ## This will require a bit of regex work.

  ## Get rid of duplicated entries
  dup_idx <- duplicated(records)
  if (sum(dup_idx) > 0) {
    message("  Dropped ", sum(dup_idx), " duplicated entries.")
  }
  records <- records[!dup_idx, ]

  message("  Saving ", savefile, " with ", nrow(records), " rows.")
  save(records, file = savefile)
  return(records)
}
